# Enhanced Neural Network Configuration
project:
  name: "house_price_prediction"
  description: "Neural network for house price prediction with enhanced modularity"
  version: "2.0"

# Pipeline configuration
pipeline:
  mode: "grid_search" # Options: "train" or "grid_search"

# Grid Search Demo configuration
grid_search_demo:
  output_dir: "data/output/grid_search_demo" # Output directory
  n_folds: 3 # Number of folds for cross-validation
  optimization_metric: "val_mse" # Metric to optimize

# Data Configuration
data:
  csv_path: "../data/input/data.csv"
  encoding: "utf-8"
  separator: null # auto-detect

  # Data loading strategy
  loading:
    total_rows: 10000 # 58000
    train_ratio: 0.7 # 70% for training
    val_ratio: 0.15 # 15% for validation
    test_ratio: 0.15 # 15% for final testing (verification)
    shuffle_data: true
    random_state: 42

  # Missing data handling
  missing_data:
    strategy: "median" # mean, median, mode, drop
    threshold: 0.7 # drop columns with >70% missing values
  # Feature engineering
  preprocessing:
    normalize_features: true
    scaler_type: "standard" # standard, robust, minmax
    handle_outliers: true # Only removes extreme price outliers

  # Columns to drop (data leakage prevention and high missing data)
  columns_to_drop:
    # Categorical columns
    - "city"
    - "property_type"
    - "ownership_type"
    - "voivodeship"
    - "quarter"

    # Data leakage columns
    - "price_per_sqm"
    - "primary_price"
    - "secondary_price"

    # High missing data columns
    - "latitude"
    - "longitude"
    - "poi_count"
    - "has_storage"

# Model Configuration
model:
  # Training parameters
  training:
    epochs: 1000
    batch_size: 32
    learning_rate: 0.001
    early_stopping:
      enabled: true
      patience: 50
      min_delta: 0.001
      restore_best_weights: true
  # Grid search parameters
  grid_search:
    optimization_metric: "val_mse" # Options: val_mse, val_mae, val_r2
    param_grid:
      hidden_layers: [[64, 32], [128, 64], [128, 64, 32]]
      dropout_rate: [0.1, 0.2, 0.3]
      learning_rate: [0.001, 0.0005]
      batch_size: [16, 32]
      activation: ["relu", "leaky_relu"]
      scaler_type: ["standard", "minmax"]
      weight_decay: [0, 0.0001] # a way to regularize the model, it penalizes large weights and helps prevent overfitting

  # Cross validation
  cross_validation:
    enabled: true
    folds: 5
    scoring: "neg_mean_absolute_error"

  # Neural Network Architecture
  architecture:
    hidden_layers: [128, 64, 32, 16]
    dropout_rate: 0.3
    activation: "relu"
    output_activation: "linear"
  # Loss and Optimization
  optimization:
    loss_function: "mse"
    optimizer: "adam"
    optimizer_params:
      weight_decay: 0.0001
    metrics: ["mae", "mse", "r2"]

# Output Configuration
output:
  results_dir: "data/output"
  save_model: true
  save_predictions: true
  save_plots: true
  save_config: true

  # Plotting options
  plots:
    loss_curve: true
    predictions_vs_actual: true
    residuals_plot: true
    feature_importance: true
    model_architecture: true
    missing_data: true
    grid_search_results: true

# Logging Configuration
logging:
  level: "INFO" # DEBUG, INFO, WARNING, ERROR
  save_to_file: true
  console_output: true
